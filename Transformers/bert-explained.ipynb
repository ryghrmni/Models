{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Materials by Francesco Periti and Elisabetta Rocchetti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers recap:\n",
    "<center><img src=\"https://pytorch.org/tutorials/_images/transformer_architecture.jpg\" width=\"30%\"/></center>\n",
    "Both the decoder and the encoder have language understanding. Idea: use only either the decoder or the encoder!\n",
    "\n",
    "Example of Transformer models in real world:\n",
    "\n",
    "- Generative Pre-Training or GPT (Radford et al., “Improving Language Understanding by Generative Pre-Training.”)\n",
    "- Bidirectional Encoder Representations from Transformers or BERT (Devlin et al., “BERT.”)\n",
    "\n",
    "GPT looks like this:\n",
    "<center><img src=\"img/gpt.png\" width=\"30%\"/></center>\n",
    "\n",
    "Main properties of GPT:\n",
    "\n",
    "- transfer learning paradigm\n",
    "- based on Transformers decoder\n",
    "\n",
    "BERT looks like this:\n",
    "<center><img src=\"img/bert.png\" width=\"30%\"/></center>\n",
    "\n",
    "Main properties of BERT:\n",
    "\n",
    "- transfer learning paradigm\n",
    "- based on Transformers encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "But... what is transfer learning? Training procedure in 2 steps:\n",
    "\n",
    "1. Pre-training: understand language $\\rightarrow$ high computational cost\n",
    "2. Fine tuning: understand how to solve task, given that I have language knowledge $\\rightarrow$ low computational cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why BERT? Unlike GPT, it is bidirectional: this means that it can learn from both left and right context! c:\n",
    "\n",
    "... but we loose the benefits of masked multi-head attention :c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "<center><img src=\"img/bert.svg\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output Representations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected input: either a single sentence or a pair of sentences. \n",
    "\n",
    "Tokenization: WordPiece tokenizer [Wu et al., “Google’s Neural Machine Translation System.”].\n",
    "\n",
    "The sequence must start with $\\text{[CLS]}$, and each sentence must end with $\\text{[SEP]}$.\n",
    "$$\\text{Raccoons love eating. They are playful.} \\rightarrow \\text{[CLS] Raccoons love eating. [SEP] They are playful. [SEP]}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details on WordPiece tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of WordPiece tokenizer is similar to Byte-Pair Encoding [Sennrich, Haddow, and Birch, “Neural Machine Translation of Rare Words with Subword Units.”] and is described in more detail in [Schuster and Nakajima, “Japanese and Korean Voice Search.”].\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Extract all the words from the dataset along with their count\n",
    "2. Split all the words into character sequences\n",
    "3. Define a vocabulary size\n",
    "4. Add all the unique characters present in the character sequences to the vocabulary\n",
    "5. Identify symbol pair having the highest score. Merge it, and add it to the vocabulary\n",
    "6. Repeat Step 5 until you reach the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "\n",
    "dataset = torchtext.datasets.AG_NEWS(split = 'train')\n",
    "batch_size = 30\n",
    "data_loader = iter(DataLoader(dataset, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3]), (\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\", 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.', 'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.', 'Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\\\but stayed near lows for the year as oil prices surged past  #36;46\\\\a barrel, offsetting a positive outlook from computer maker\\\\Dell Inc. (DELL.O)', \"Money Funds Fell in Latest Week (AP) AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\", 'Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.', 'Safety Net (Forbes.com) Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.', \"Wall St. Bears Claw Back Into the Black  NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\", \"Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\", \"No Need for OPEC to Pump More-Iran Gov  TEHRAN (Reuters) - OPEC can do nothing to douse scorching  oil prices when markets are already oversupplied by 2.8 million  barrels per day (bpd) of crude, Iran's OPEC governor said  Saturday, warning that prices could fall sharply.\", 'Non-OPEC Nations Should Up Output-Purnomo  JAKARTA (Reuters) - Non-OPEC oil exporters should consider  increasing output to cool record crude prices, OPEC President  Purnomo Yusgiantoro said on Sunday.', \"Google IPO Auction Off to Rocky Start  WASHINGTON/NEW YORK (Reuters) - The auction for Google  Inc.'s highly anticipated initial public offering got off to a  rocky start on Friday after the Web search company sidestepped  a bullet from U.S. securities regulators.\", \"Dollar Falls Broadly on Record Trade Gap  NEW YORK (Reuters) - The dollar tumbled broadly on Friday  after data showing a record U.S. trade deficit in June cast  fresh doubts on the economy's recovery and its ability to draw  foreign capital to fund the growing gap.\", \"Rescuing an Old Saver If you think you may need to help your elderly relatives with their finances, don't be shy about having the money talk -- soon.\", 'Kids Rule for Back-to-School The purchasing power of kids is a big part of why the back-to-school season has become such a huge marketing phenomenon.', \"In a Down Market, Head Toward Value Funds There is little cause for celebration in the stock market these days, but investors in value-focused mutual funds have reason to feel a bit smug -- if only because they've lost less than the folks who stuck with growth.\", 'US trade deficit swells in June The US trade deficit has exploded 19 to a record \\\\$55.8bn as oil costs drove imports higher, according to a latest figures.', \"Shell 'could be target for Total' Oil giant Shell could be bracing itself for a takeover attempt, possibly from French rival Total, a  press report claims.\", \"Google IPO faces Playboy slip-up The bidding gets underway for Google's public offering, despite last-minute worries over an interview with its bosses in Playboy magazine.\", 'Eurozone economy keeps growing Official figures show the 12-nation eurozone economy continues to grow, but there are warnings it may slow down later in the year.', 'Expansion slows in Japan Economic growth in Japan slows down as the country experiences a drop in domestic and corporate spending.', 'Rand falls on shock SA rate cut Interest rates are trimmed to 7.5 by the South African central bank,  but the lack of warning hits the rand and surprises markets.', 'Car prices down across the board The cost of buying both new and second hand cars fell sharply over the past five years, a new survey has found.', \"South Korea lowers interest rates South Korea's central bank cuts interest rates by a quarter percentage point to 3.5 in a bid to drive growth in the economy.\", 'Google auction begins on Friday An auction of shares in Google, the web search engine which could be floated for as much as \\\\$36bn, takes place on Friday.', 'HP shares tumble on profit news Hewlett-Packard shares fall after disappointing third-quarter profits, while the firm warns the final quarter will also fall short of expectations.', 'Mauritian textile firm cuts jobs One of the oldest textile operators on the Indian Ocean island of Mauritius last week shut seven factories and cut 900 jobs.', 'Chad seeks refugee aid from IMF Chad asks the IMF for a loan to pay for looking after more than 100,000 refugees from conflict-torn Darfur in western Sudan.')]\n"
     ]
    }
   ],
   "source": [
    "for s in data_loader:\n",
    "    print(s)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "class WordPieceTokenizer:\n",
    "    def __init__(self, vocabulary_size):\n",
    "        self.word_counter = Counter()\n",
    "        #3\n",
    "        self.vocab_size = vocabulary_size\n",
    "        #4 and 5\n",
    "        self.vocab = Counter()\n",
    "        \n",
    "    #1\n",
    "    def extract_words(self, batch):\n",
    "        res_batch = []\n",
    "        for sentence in batch:\n",
    "            tokenized = nltk.word_tokenize(sentence.lower().strip())\n",
    "            self.word_counter.update(tokenized)\n",
    "            res_batch.append(tokenized)\n",
    "        return res_batch\n",
    "    \n",
    "    #2\n",
    "    def split_char(self, batch):\n",
    "        res_batch = []\n",
    "        for sentence in batch:\n",
    "            res_batch.append([[c for c in word] for word in sentence])\n",
    "        return res_batch\n",
    "    \n",
    "    #4\n",
    "    def add_unique_chars(self, batch):\n",
    "        batch_split = self.split_char(batch)\n",
    "        for sentence in batch_split:\n",
    "            for word in sentence:\n",
    "                self.vocab.update(word)\n",
    "    \n",
    "    #5\n",
    "    def count_likelihood(self):\n",
    "        pair_counter = Counter()     \n",
    "        for word, word_count in self.word_counter.items():\n",
    "            word = self.word_tokenize(word)\n",
    "            if len(word) < 2: continue \n",
    "            for i in range(len(word)-1):\n",
    "                pair_counter.update([(word[i], word[i+1])] * word_count)\n",
    "        likelihoods = {k: v/(self.vocab[k[0]]*self.vocab[k[1]]) for k, v in pair_counter.items()}\n",
    "        likelihoods = sorted(likelihoods.items(), key=lambda x: x[1])\n",
    "        return likelihoods, pair_counter\n",
    "    \n",
    "    def add_frequent(self, logging = False):\n",
    "        while len(self.vocab) < self.vocab_size:\n",
    "            likelihoods, counter = self.count_likelihood()\n",
    "            found_next = False\n",
    "            while not found_next:\n",
    "                if not likelihoods: return len(self.vocab) < self.vocab_size\n",
    "                new_frequent_split = likelihoods.pop()\n",
    "                if not f'{new_frequent_split[0][0]}{new_frequent_split[0][1]}' in self.vocab: found_next = True\n",
    "            self.vocab.update({f'{new_frequent_split[0][0]}{new_frequent_split[0][1]}':counter[new_frequent_split[0]]})\n",
    "            if logging: \n",
    "                print(f'The pair \"{new_frequent_split[0][0]}{new_frequent_split[0][1]}\" having score {new_frequent_split[1]} has been added')\n",
    "                print(f'Updated vocabulary: {self.vocab}')\n",
    "        return len(self.vocab) == self.vocab_size\n",
    "    \n",
    "    def word_tokenize(self, word):\n",
    "        if len(word)==1:\n",
    "            return [word]\n",
    "        splits = []\n",
    "        i = 0\n",
    "        word_temp = word\n",
    "        while ''.join(splits) !=  word:\n",
    "            if i < len(word_temp):\n",
    "                split = word_temp[0:len(word_temp)-i]\n",
    "                if split in self.vocab:\n",
    "                    splits.append(split)\n",
    "                    word_temp = word_temp[len(split):]\n",
    "                    i=0\n",
    "                else:\n",
    "                    i = i+1\n",
    "            else:\n",
    "                splits = splits + [word_temp]\n",
    "        return splits\n",
    "    \n",
    "    def tokenize(self, sentence):\n",
    "        sentence_tokenized = []\n",
    "        for word in nltk.word_tokenize(sentence.lower().strip()):\n",
    "            sentence_tokenized.append(self.word_tokenize(word))\n",
    "        return sentence_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'home'], ['house'], ['horse'], ['universe']]\n",
      "Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1})\n",
      "The pair \"un\" having score 0.5 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1})\n",
      "The pair \"iv\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1})\n",
      "The pair \"univ\" having score 1.0 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1})\n",
      "The pair \"om\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1, 'om': 1})\n",
      "The pair \"hom\" having score 0.25 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1, 'om': 1, 'hom': 1})\n",
      "The pair \"th\" having score 0.25 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'th': 1})\n",
      "The pair \"thi\" having score 0.3333333333333333 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'th': 1, 'thi': 1})\n",
      "The pair \"unive\" having score 0.2 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'th': 1, 'thi': 1, 'unive': 1})\n",
      "The pair \"univer\" having score 0.5 has been added\n",
      "Updated vocabulary: Counter({'s': 5, 'e': 5, 'h': 4, 'i': 3, 'o': 3, 'u': 2, 'r': 2, 't': 1, 'm': 1, 'n': 1, 'v': 1, 'un': 1, 'iv': 1, 'univ': 1, 'om': 1, 'hom': 1, 'th': 1, 'thi': 1, 'unive': 1, 'univer': 1})\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "wptokenizer = WordPieceTokenizer(vocabulary_size=20)\n",
    "b = ['this is home', 'house', 'horse', 'universe']\n",
    "d = wptokenizer.extract_words(b)\n",
    "print(d)\n",
    "wptokenizer.add_unique_chars(d)\n",
    "print(wptokenizer.vocab)\n",
    "wptokenizer.add_frequent(logging = True)\n",
    "print(len(wptokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'o', 'r', 's', 'e']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wptokenizer.word_tokenize('horse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wptokenizer = WordPieceTokenizer(vocabulary_size=10000)\n",
    "_, b = next(data_loader)\n",
    "d = wptokenizer.extract_words(b)\n",
    "wptokenizer.add_unique_chars(d)\n",
    "wptokenizer.add_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: Cassini Spacecraft Sees Saturn Lightning (AP) AP - The Cassini spacecraft's mission to Saturn has revealed a new radiation belt around the ringed planet and found that lightning in its atmosphere is occurring in different patterns than it did when NASA's Voyagers flew by in the early 1980s, scientists said.\n",
      "Tokenized:[['cas', 's', 'in', 'i'], ['spacecraft'], ['sees'], ['s', 'atur', 'n'], ['light', 'n', 'ing'], ['('], ['ap'], [')'], ['ap'], ['-'], ['the'], ['cas', 's', 'in', 'i'], ['spacecraft'], [\"'s\"], ['mission'], ['to'], ['s', 'atur', 'n'], ['has'], ['r', 'e', 've', 'a', 'led'], ['a'], ['new'], ['r', 'a', 'd', 'i', 'ation'], ['bel', 't'], ['around'], ['the'], ['r', 'ing', 'ed'], ['planet'], ['and'], ['found'], ['that'], ['light', 'n', 'ing'], ['in'], ['its'], ['atm', 'o', 'sp', 'here'], ['is'], ['o', 'ccur', 'r', 'ing'], ['in'], ['d', 'if', 'fe', 'r', 'e', 'n', 't'], ['p', 'at', 't', 'e', 'r', 'n', 's'], ['than'], ['it'], ['d', 'id'], ['when'], ['nasa'], [\"'s\"], ['v', 'o', 'y', 'age', 'r', 's'], ['fl', 'ew'], ['by'], ['in'], ['the'], ['early'], ['1', '9', '8', '0', 's'], [','], ['scientists'], ['said'], ['.']]\n"
     ]
    }
   ],
   "source": [
    "example_sentence = next(data_loader)[1][2]\n",
    "tokenized = wptokenizer.tokenize(example_sentence)\n",
    "print(f'Example sentence: {example_sentence}')\n",
    "print(f'Tokenized:{tokenized}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: Science, Politics Collide in Election Year (AP) AP - With more than 4,000 scientists, including 48 Nobel Prize winners, having signed a statement opposing the Bush administration's use of scientific advice, this election year is seeing a new development in the uneasy relationship between science and politics.\n",
      "Tokenized:[['s', 'c', 'i', 'e', 'n', 'c', 'e'], [','], ['politic', 's'], ['co', 'll', 'id', 'e'], ['in'], ['election'], ['year'], ['('], ['a', 'p'], [')'], ['a', 'p'], ['-'], ['with'], ['more'], ['than'], ['4', ',000'], ['scientists'], [','], ['including'], ['4', '8'], ['no', 'be', 'l'], ['pri', 'z', 'e'], ['winn', 'ers'], [','], ['having'], ['s', 'i', 'g', 'ned'], ['a'], ['state', 'm', 'e', 'n', 't'], ['op', 'po', 'sing'], ['the'], ['bush'], ['ad', 'm', 'in', 'ist', 'r', 'at', 'ion'], [\"'s\"], ['use'], ['of'], ['s', 'c', 'i', 'e', 'n', 't', 'if', 'i', 'c'], ['ad', 'vic', 'e'], [','], ['this'], ['election'], ['year'], ['is'], ['s', 'e', 'ein', 'g'], ['a'], ['new'], ['de', 've', 'lo', 'p', 'm', 'e', 'n', 't'], ['in'], ['the'], ['u', 'n', 'e', 'as', 'y'], ['r', 'e', 'l', 'at', 'ion', 's', 'hip'], ['between'], ['s', 'c', 'i', 'e', 'n', 'c', 'e'], ['and'], ['politic', 's'], ['.']]\n"
     ]
    }
   ],
   "source": [
    "example_sentence = next(data_loader)[1][0]\n",
    "tokenized = wptokenizer.tokenize(example_sentence)\n",
    "print(f'Example sentence: {example_sentence}')\n",
    "print(f'Tokenized:{tokenized}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: Do you like raccons?\n",
      "Tokenized:['do', 'you', 'like', 'ra', '##cco', '##ns', '?']\n"
     ]
    }
   ],
   "source": [
    "#sentences = example_sentence.split('.')\n",
    "example_sentence = 'Do you like raccons? Yes, I love them!'\n",
    "example_sentence_1, example_sentence_2 = 'Do you like raccons?', 'Yes, I love them!'\n",
    "tokenized_1 = bert_tokenizer.tokenize(example_sentence_1)\n",
    "tokenized_2 = bert_tokenizer.tokenize(example_sentence_2)\n",
    "print(f'Example sentence: {example_sentence_1}')\n",
    "print(f'Tokenized:{tokenized_1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tokens, we can extract embeddings for them (as with the Transformers!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids: [101, 2079, 2017, 2066, 10958, 21408, 3619, 1029, 102, 2748, 1010, 1045, 2293, 2068, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_output = bert_tokenizer(example_sentence_1, example_sentence_2, padding = 'max_length')\n",
    "print(f'Input ids: {tokenizer_output[\"input_ids\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens (512): ['[CLS]', 'do', 'you', 'like', 'ra', '##cco', '##ns', '?', '[SEP]', 'yes', ',', 'i', 'love', 'them', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "tokens = bert_tokenizer.convert_ids_to_tokens(tokenizer_output[\"input_ids\"])\n",
    "print(f'Input tokens ({len(tokens)}): {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 768 #as in the original paper\n",
    "max_seq_len = 512\n",
    "\n",
    "embedding_layer = nn.Embedding(bert_tokenizer.vocab_size, d_model)\n",
    "input_embedding = embedding_layer(torch.IntTensor(tokenizer_output[\"input_ids\"]))\n",
    "input_embedding.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        i = torch.arange(0,self.d_model,2, dtype=torch.float).repeat_interleave(2)[:self.d_model]\n",
    "        denominator = torch.pow(10000, 2*i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
    "        sin_cos_argument = position/denominator\n",
    "        PE = torch.zeros(size = sin_cos_argument.shape)\n",
    "        PE[:, 0::2] = torch.sin(sin_cos_argument[:, 0::2])\n",
    "        PE[:, 1::2] = torch.cos(sin_cos_argument[:, 1::2])\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0252,  1.9739,  1.2500,  ...,  0.5327, -0.6666,  1.4998],\n",
       "        [ 2.3795,  0.6082, -0.0173,  ...,  1.1040, -0.5483,  1.4453],\n",
       "        [ 2.6720,  0.2186,  0.5914,  ...,  1.9150,  1.4443,  0.0669],\n",
       "        ...,\n",
       "        [ 1.6713,  0.2841,  1.9693,  ..., -0.0180, -0.8147,  1.1864],\n",
       "        [ 2.4827, -0.2268,  1.7335,  ..., -0.0180, -0.8147,  1.1864],\n",
       "        [ 2.4911, -1.1856,  0.8741,  ..., -0.0180, -0.8147,  1.1864]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_output = bert_tokenizer(example_sentence_1, example_sentence_2, truncation=True, padding='max_length', add_special_tokens=True)\n",
    "input_embedding = embedding_layer(torch.IntTensor(tokenizer_output[\"input_ids\"]))\n",
    "print(input_embedding.size())\n",
    "\n",
    "positional_encoding_layer = PositionalEncoding(max_sequence_length=max_seq_len, d_model=d_model)\n",
    "input_embedding = input_embedding + positional_encoding_layer()\n",
    "input_embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = torch.tile(torch.IntTensor(tokenizer_output['token_type_ids']).unsqueeze(1), (1, d_model))\n",
    "print(sentence_embeddings.size())\n",
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0252,  1.9739,  1.2500,  ...,  0.5327, -0.6666,  1.4998],\n",
       "        [ 2.3795,  0.6082, -0.0173,  ...,  1.1040, -0.5483,  1.4453],\n",
       "        [ 2.6720,  0.2186,  0.5914,  ...,  1.9150,  1.4443,  0.0669],\n",
       "        ...,\n",
       "        [ 1.6713,  0.2841,  1.9693,  ..., -0.0180, -0.8147,  1.1864],\n",
       "        [ 2.4827, -0.2268,  1.7335,  ..., -0.0180, -0.8147,  1.1864],\n",
       "        [ 2.4911, -1.1856,  0.8741,  ..., -0.0180, -0.8147,  1.1864]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = input_embedding + sentence_embeddings\n",
    "input_embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! BERT is bidirectional: this allows each word to \"see itself\", and the model could trivially predict the target word in a multi-layered context.\n",
    "\n",
    "*SOLUTION*: mask some percentage of the input tokens at random, and then predict those masked tokens! c:\n",
    "\n",
    "This is called **Masked Language Modeling (MLM)**, and it is one of the two pre-training objectives BERT has.\n",
    "\n",
    "Usually, language models are trained to predict each word in a sentence; here, BERT must predict only the masked tokens.\n",
    "\n",
    "**Masking procedure**\n",
    "\n",
    "0. Take 15% of the tokens in the input sentence\n",
    "1. $\\rightarrow$ 80% of those tokens will be replaced with the special token $\\text{[MASK]}$\n",
    "2. $\\rightarrow$ 10% of those tokens will be replaced with a random token\n",
    "3. $\\rightarrow$ 10% of those tokens will remain unchanged\n",
    "\n",
    "**Why 80-10-10?**\n",
    "\n",
    "There may be a mismatch between the pre-training and fine-tuning tasks because the latter does not involve predicting masked words in most of the downstream tasks (e.g. sentiment analysis). The model should be good not only in predicting masked tokens, but also as pre-trained model for other tasks. The advantage of this procedure is that the Transformer encoder does not know which words it will be asked to predict or which have been replaced by random words, so it is forced to keep a distributional contextual representation of every input token.\n",
    "\n",
    "- Just using the $\\text{[MASK]}$ token resulted in the model learning very little about the context of the surrounding words. This seems to occur since the model knows it can “forget” all the information about the surrounding words and focus only on the target word.\n",
    "\n",
    "- If you use the $\\text{[MASK]}$ token 80% of the time and the right word 20% of the time, the model will know that when the [MASK] is not there, then the word is correct. The network has to predict the token, but it actually gets the answer already as input. Thus, it needs to learn nothing, since it knows the non-masked token is always correct.\n",
    "\n",
    "- If you use the $\\text{[MASK]}$ token 80% of the time and a wrong word 20% of the time, the model will know when the $\\text{[MASK]}$ doesn’t appear the selected token is a wrong one, and it will just treat it like another $\\text{[MASK]}$, i.e. you would likely encounter the same problem of before (100% $\\text{[MASK]}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def mask_sentence(sentence1, sentence2 = None, add_special_tokens = True, padding = 'max_length'):\n",
    "    if sentence2:\n",
    "        inputs = bert_tokenizer(sentence1, sentence2, return_tensors='pt', add_special_tokens=add_special_tokens, truncation=True, padding=padding)\n",
    "    else:\n",
    "        inputs = bert_tokenizer(sentence1, return_tensors='pt', add_special_tokens=add_special_tokens, truncation=True, padding=padding)\n",
    "    \n",
    "    inputs['labels'] = inputs.input_ids.detach().clone() #for training\n",
    "    \n",
    "    rand = torch.rand(inputs.input_ids.squeeze().shape) #Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)\n",
    "    mask_arr = (rand < 0.15) * (inputs.input_ids.squeeze() != 101) * (inputs.input_ids.squeeze() != 102) * (inputs.input_ids.squeeze() != 0) #101 is [CLS] and 102 is [SEP] and 0 is [PAD]\n",
    "    index_to_mask = torch.flatten(mask_arr.nonzero()).tolist()\n",
    "    \n",
    "    index_to_mask_shuffle = random.sample(index_to_mask, int(len(index_to_mask)-(0.1 * len(index_to_mask))))\n",
    "    to_mask = int(0.8*len(index_to_mask))\n",
    "    inputs.input_ids[0, index_to_mask_shuffle[:to_mask]] = 103 #[MASK] token\n",
    "    inputs.input_ids[0, index_to_mask_shuffle[to_mask:]] = torch.LongTensor(random.sample(list(bert_tokenizer.vocab.values()), len(index_to_mask_shuffle)-to_mask)) #random token\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Do you like raccons? Yes, I love them!\n",
      "Masked sentence: [CLS] do you [MASK] ra [MASK] ##ns ? [SEP] yes , i [MASK] them ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "masked_sentence = mask_sentence(example_sentence_1, example_sentence_2)\n",
    "print(f'Original sentence: {example_sentence_1} {example_sentence_2}')\n",
    "print(f'Masked sentence: {\" \".join(bert_tokenizer.convert_ids_to_tokens(*masked_sentence.input_ids))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline with masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0252,  1.9739,  1.2500,  ...,  0.5327, -0.6666,  1.4998],\n",
       "         [ 2.3795,  0.6082, -0.0173,  ...,  1.1040, -0.5483,  1.4453],\n",
       "         [ 2.6720,  0.2186,  0.5914,  ...,  1.9150,  1.4443,  0.0669],\n",
       "         ...,\n",
       "         [ 1.6713,  0.2841,  1.9693,  ..., -0.0180, -0.8147,  1.1864],\n",
       "         [ 2.4827, -0.2268,  1.7335,  ..., -0.0180, -0.8147,  1.1864],\n",
       "         [ 2.4911, -1.1856,  0.8741,  ..., -0.0180, -0.8147,  1.1864]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input_masked = mask_sentence(example_sentence_1, example_sentence_2)\n",
    "token_embeddings = embedding_layer(tokenized_input_masked['input_ids'])\n",
    "position_embeddings = positional_encoding_layer()\n",
    "sentence_embeddings = torch.tile(tokenized_input_masked['token_type_ids'].permute(1,0), (1, d_model)).unsqueeze(0)\n",
    "embeddings = token_embeddings + position_embeddings + sentence_embeddings\n",
    "print(embeddings.size())\n",
    "embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During pre-training, BERT will evaluate the loss of these masked tokens, and it will backpropagate it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second pre-training objective is called **Next Sentence Prediction (NSP)**. \n",
    "\n",
    "Many important downstream tasks such as Question Answering (QA) and Natural Language Inference (NLI) are based on understanding the relationship between two sentences, which is not directly captured by language modeling.\n",
    "\n",
    "When pre-traininig for a binarized NSP task, we choose the sentences A and B for each pretraining example,ì so that 50% of the time B is the actual next sentence that follows A (labeled as IsNext), and 50% of the time it is a random sentence from the corpus (labeled as NotNext).\n",
    "\n",
    "$\\text{[CLS]}$ is used for NSP.\n",
    "\n",
    "<center><img src=\"img/bert_pretrain_2.svg\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use task-specific data and additional output layers taking as input BERT's output.\n",
    "\n",
    "**Question Answering with Stanford Question Answering Dataset (SQuAD)**\n",
    "<center><img src=\"img/bert_finetune_squad.svg\"/></center>\n",
    "\n",
    "**Entailment with MNLI**\n",
    "<center><img src=\"img/bert_finetune_mnli.svg\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on: BERT!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is (finally) dedicated to some real-world BERT use cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model_mlm = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "print(bert_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 30522])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model_mlm(**masked_sentence).logits\n",
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  5, 12])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve index of [MASK]\n",
    "mask_token_index = (masked_sentence.input_ids == bert_tokenizer.mask_token_id)[0].nonzero().squeeze()\n",
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2812, 22414,  2113])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_token_id \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m0\u001b[39m, mask_token_index]\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_token_id)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbert_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_ids_to_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_token_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/envs/nlp/lib/python3.9/site-packages/transformers/tokenization_utils.py:976\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    974\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[0;32m--> 976\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_special_tokens \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_ids:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "print(predicted_token_id)\n",
    "print(bert_tokenizer.convert_ids_to_tokens([predicted_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] do you like raccons? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] do you like ra [MASK]ns? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] do you like rabbans? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.where(masked_sentence.input_ids == bert_tokenizer.mask_token_id, logits[0, :].argmax(axis=-1), masked_sentence.input_ids)[0]\n",
    "print(bert_tokenizer.decode(masked_sentence.labels[0]))\n",
    "print(bert_tokenizer.decode(masked_sentence.input_ids[0]))\n",
    "print(bert_tokenizer.decode(prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mlm_pipeline = pipeline('fill-mask', model=model_mlm, tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] do you like raccons? [SEP] yes, [MASK] love them! [SEP]'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mask_sentence = mask_sentence(example_sentence_1, example_sentence_2, add_special_tokens = True, padding = False)\n",
    "pipeline_mask_sentence = bert_tokenizer.decode(pipeline_mask_sentence.input_ids[0])\n",
    "pipeline_mask_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.928654670715332,\n",
       "  'token': 1045,\n",
       "  'token_str': 'i',\n",
       "  'sequence': 'do you like raccons? yes, i love them!'},\n",
       " {'score': 0.053255245089530945,\n",
       "  'token': 2017,\n",
       "  'token_str': 'you',\n",
       "  'sequence': 'do you like raccons? yes, you love them!'},\n",
       " {'score': 0.013073953799903393,\n",
       "  'token': 2057,\n",
       "  'token_str': 'we',\n",
       "  'sequence': 'do you like raccons? yes, we love them!'},\n",
       " {'score': 0.0026619471609592438,\n",
       "  'token': 2027,\n",
       "  'token_str': 'they',\n",
       "  'sequence': 'do you like raccons? yes, they love them!'},\n",
       " {'score': 0.0003746188012883067,\n",
       "  'token': 1998,\n",
       "  'token_str': 'and',\n",
       "  'sequence': 'do you like raccons? yes, and love them!'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_pipeline(pipeline_mask_sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForNextSentencePrediction\n",
    "\n",
    "model_nsp = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels (torch.LongTensor of shape (batch_size,), optional) — Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair (see input_ids docstring). Indices should be in [0, 1]:\n",
    "- 0 indicates sequence B is a continuation of sequence A,\n",
    "- 1 indicates sequence B is a random sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.3850, -2.3090]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "masked_sentence['labels'] = torch.LongTensor([0])\n",
    "outputs = model_nsp(**masked_sentence)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(torch.argmax(logits)) #isNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0729,  5.9056]], grad_fn=<AddmmBackward0>)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "#next_sentence = \"This is what happens in Italian restaurants.\"\n",
    "encoding = bert_tokenizer(prompt, next_sentence, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model_nsp(**encoding, labels=torch.LongTensor([1]))\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(torch.argmax(logits))# next sentence was random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence Classification with MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnli_dataset = load_dataset('multi_nli', split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promptID': 60529,\n",
       " 'pairID': '60529c',\n",
       " 'premise': \"At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\",\n",
       " 'premise_binary_parse': \"( ( At ( ( the end ) ( of Rue ) ) ) ( ( des Francs-Bourgeois ) ( ( is ( what ( many ( consider ( to ( ( be ( ( ( ( ( the ( city 's ) ) ( ( most handsome ) ( residential square ) ) ) , ) ( the ( Place ( des Vosges ) ) ) ) , ) ) ( with ( its ( stone ( and ( red ( brick facades ) ) ) ) ) ) ) ) ) ) ) ) . ) ) )\",\n",
       " 'premise_parse': \"(ROOT (S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NNP Rue))))) (NP (NNP des) (NNP Francs-Bourgeois)) (VP (VBZ is) (SBAR (WHNP (WP what)) (S (NP (DT many)) (VP (VBP consider) (S (VP (TO to) (VP (VB be) (NP (NP (NP (DT the) (NN city) (POS 's)) (ADJP (RBS most) (JJ handsome)) (JJ residential) (NN square)) (, ,) (NP (DT the) (NNP Place) (NNP des) (NNPS Vosges)) (, ,)) (PP (IN with) (NP (PRP$ its) (NN stone) (CC and) (JJ red) (NN brick) (NNS facades)))))))))) (. .)))\",\n",
       " 'hypothesis': 'Place des Vosges is constructed entirely of gray marble.',\n",
       " 'hypothesis_binary_parse': '( ( Place ( des Vosges ) ) ( ( is ( ( constructed entirely ) ( of ( gray marble ) ) ) ) . ) )',\n",
       " 'hypothesis_parse': '(ROOT (S (NP (NNP Place) (FW des) (NNP Vosges)) (VP (VBZ is) (VP (VBN constructed) (ADVP (RB entirely)) (PP (IN of) (NP (JJ gray) (NN marble))))) (. .)))',\n",
       " 'genre': 'travel',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_mnli = mnli_dataset[9] #entailment (0), neutral (1), contradiction (2)\n",
    "example_mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\n",
      "Place des Vosges is constructed entirely of stone and bricks.\n"
     ]
    }
   ],
   "source": [
    "print(example_mnli['premise'])\n",
    "example_mnli['hypothesis'] = \"Place des Vosges is constructed entirely of stone and bricks.\"\n",
    "print(example_mnli['hypothesis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnli_preprocess_function(examples):\n",
    "    return bert_tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding = True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\n",
      "Hypothesis: Place des Vosges is constructed entirely of stone and bricks.\n",
      "After preprocessing: [CLS] at the end of rue des francs - bourgeois is what many consider to be the city's most handsome residential square, the place des vosges, with its stone and red brick facades. [SEP] place des vosges is constructed entirely of stone and bricks. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(f'Premise: {example_mnli[\"premise\"]}')\n",
    "print(f'Hypothesis: {example_mnli[\"hypothesis\"]}')\n",
    "example_mnli_processed = mnli_preprocess_function(example_mnli)\n",
    "print(f'After preprocessing: {bert_tokenizer.decode(example_mnli_processed[\"input_ids\"][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_mnli_dataset = mnli_dataset.map(mnli_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_mnli = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-MNLI\") #entailment (1), neutral (2), contradiction (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2080,  0.2117,  1.4080]], grad_fn=<AddmmBackward0>)\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "outputs = model_mnli(**example_mnli_processed)\n",
    "logits = outputs.logits\n",
    "print(logits)\n",
    "print(torch.argmax(logits))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Answering with SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810e42ab89a444c3b991d525a04dc17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3930dce905da41aca24ed8e496a5a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3204fcfa31ed4edb91051641da5f2118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811397e0d3c046b49cd47714aeb821b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16f7cec683b42a8b56b7946090852cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad_dataset = load_dataset(\"squad\", split = 'train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_example = squad_dataset[0]\n",
    "squad_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at csarron/bert-base-uncased-squad-v1 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "  \"question-answering\",\n",
    "  model=\"csarron/bert-base-uncased-squad-v1\",\n",
    "  tokenizer=\"csarron/bert-base-uncased-squad-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9795625805854797, 'start': 515, 'end': 541, 'answer': 'Saint Bernadette Soubirous'}\n"
     ]
    }
   ],
   "source": [
    "predictions = qa_pipeline({\n",
    "  'context': squad_example['context'],\n",
    "  'question': squad_example['question']\n",
    "})\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Variants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/bert_models.png\" width = \"70%\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Extensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/bert_variants.png\" width = \"70%\"/></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers:\n",
    "- Radford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” 2019, 12.\n",
    "- Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics, 2019. https://doi.org/10.18653/v1/N19-1423.\n",
    "- Wu, Yonghui, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, et al. “Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation.” ArXiv:1609.08144 [Cs], October 8, 2016. http://arxiv.org/abs/1609.08144.\n",
    "- Sennrich, Rico, Barry Haddow, and Alexandra Birch. “Neural Machine Translation of Rare Words with Subword Units.” arXiv, June 10, 2016. https://doi.org/10.48550/arXiv.1508.07909.\n",
    "- Schuster, Mike, and Kaisuke Nakajima. “Japanese and Korean Voice Search.” In 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5149–52, 2012. https://doi.org/10.1109/ICASSP.2012.6289079.\n",
    "- Liu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. “RoBERTa: A Robustly Optimized BERT Pretraining Approach.” ArXiv:1907.11692 [Cs], July 26, 2019. http://arxiv.org/abs/1907.11692.\n",
    "- Sanh, Victor, Lysandre Debut, Julien Chaumond, and Thomas Wolf. “DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter.” arXiv, February 29, 2020. https://doi.org/10.48550/arXiv.1910.01108.\n",
    "\n",
    "Online resources / tutorials:\n",
    "- https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/bert#bert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
